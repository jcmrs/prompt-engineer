# Jules Prompting Guide for AI

## 1. Overview

This document provides a comprehensive guide for AI models to generate effective prompts for Jules, a sophisticated, asynchronous software engineering AI. The goal is to enable other AIs to understand Jules's capabilities, methodologies, and best practices to produce optimal instructions by integrating knowledge from the official Jules documentation.

## 2. Core Principles for Prompting Jules

*   **Clarity and Specificity:** Prompts should be unambiguous and provide concrete, machine-readable details.
*   **Completeness:** Include all necessary context, repository information, constraints, and expected outcomes.
*   **Structured Format:** Use markdown (headings, lists, code blocks) to structure complex requests for reliable parsing.

## 3. The Jules Task Lifecycle

Jules operates on a distinct, human-in-the-loop lifecycle. Prompts should be designed to support this workflow.

### 3.1. Phase 1: The Prompt & Plan Generation
A task begins when a prompt is submitted. Jules analyzes the prompt, explores the codebase using its tools, and generates a detailed, step-by-step plan.
*   **Instruction:** For complex tasks, the prompt should explicitly instruct Jules to create a plan.
*   **Example:** "Your task is to add a new REST endpoint. First, create a plan that includes steps for: creating the handler, defining the route, writing a unit test, and updating the documentation."

### 3.2. Phase 2: Plan Approval
The user reviews the plan generated by Jules. No code is written until the plan is approved. This is a critical control step.

### 3.3. Phase 3: Execution
Once the plan is approved, Jules executes each step sequentially. It uses a variety of tools to modify code, run commands, and verify its work. After each action, Jules uses a read-only tool (like `read_file`) to confirm the change was applied correctly.

## 4. Environment and Repository Context

Providing context is critical for success. Jules can be given context in two primary ways.

### 4.1. Environment Setup Scripts
For repositories that require specific build steps, environment variables, or dependency installations, a setup script can be provided in the prompt.
*   **Instruction:** If a repository has a non-standard setup, the prompt must include the necessary shell commands.
*   **Example:**
    ```markdown
    **Environment Setup:**
    Before starting, run the following commands:
    ```bash
    export DATABASE_URL=test.db
    npm install
    npm run build
    ```
    ```

### 4.2. The `AGENTS.md` File
Jules automatically looks for a file named `AGENTS.md` in the repository's root. This file is a powerful mechanism for providing persistent, repository-specific instructions.
*   **Content:** This file can describe build processes, testing conventions, architectural patterns, or how to interact with internal tools.
*   **Instruction:** For any ongoing work in a repository, referencing its `AGENTS.md` is a best practice. Example: "Implement the `DeleteUser` endpoint following the pattern described in `AGENTS.md`."

## 5. Integrated Prompting Examples

The following examples are integrated from the [Jules Awesome Prompts repository](https://github.com/google-labs-code/jules-awesome-list) and demonstrate best practices for various task categories.

### 5.1. Everyday Dev Tasks

**Objective:** Modernize a legacy JavaScript codebase by refactoring from CommonJS to ES Modules.

```markdown
// Convert all CommonJS modules in the `src/utils` directory to ES Modules.

**Context:**
- **Directory:** `src/utils`
- **Current Pattern:** The files in this directory use `require()` for imports and `module.exports` for exports.
- **Target Pattern:** Modern ES Module syntax (`import` and `export`).

**Requirements:**
1.  Recursively find all `.js` files in `src/utils`.
2.  For each file, rewrite the `require()` statements to `import`.
3.  Rewrite the `module.exports` statements to use `export default` or named `export`.
4.  Run the linter (`npm run lint -- --fix`) to correct any stylistic issues after the conversion.
5.  Ensure that all existing tests continue to pass by running `npm test`.
```

### 5.2. Debugging

**Objective:** Diagnose and fix a runtime error in a Python script.

```markdown
// Help me fix a `KeyError` in `process_data.py`.

**Context:**
- **File:** `scripts/process_data.py`
- **Error:** When the script is run with an input file that is missing the 'user_id' field in a record, it crashes with a `KeyError`.
- **Log Snippet:** `KeyError: 'user_id'`

**Requirements:**
1.  Analyze the `process_data` function in `scripts/process_data.py`.
2.  Add defensive code to check if the 'user_id' key exists in each record before accessing it.
3.  If the key is missing, the script should log a warning message and skip that record instead of crashing.
4.  Add a new unit test in `tests/test_process_data.py` that specifically covers this missing key scenario.
```

### 5.3. Testing

**Objective:** Write a test for a frontend component that mocks an external API call.

```markdown
// Write a test for the `UserProfile` React component that mocks the `fetch` API call.

**Context:**
- **Component:** `src/components/UserProfile.js`
- **Behavior:** The component fetches user data from `/api/user/123` and displays the user's name.

**Requirements:**
1.  Create a new test file `src/components/UserProfile.test.js`.
2.  Using Jest, write a test that renders the `UserProfile` component.
3.  Mock the global `fetch` function to return a mock user object (e.g., `{ name: 'John Doe' }`) for the `/api/user/123` endpoint.
4.  Assert that the component correctly renders the user's name after the mock API call resolves.
```

### 5.4. AI-Native Tasks

**Objective:** Use Jules to analyze a codebase and identify technical debt.

```markdown
// Analyze the `legacy_service.java` file and identify areas of technical debt.

**Context:**
- **File:** `src/main/java/com/example/legacy/legacy_service.java`
- **Goal:** This file is old and difficult to maintain. We need a structured analysis before refactoring.

**Instructions:**
1.  Read the entire content of the specified file.
2.  Identify and list potential areas of technical debt. For each item, provide a code snippet and a brief explanation.
3.  Categorize the identified debt into one of the following:
    - **Code Complexity:** (e.g., deeply nested loops, high cyclomatic complexity)
    - **Duplicate Logic:** (e.g., repeated code blocks that could be extracted)
    - **Missing Tests:** (e.g., public methods with no test coverage)
    - **Outdated Patterns:** (e.g., using deprecated library functions)
4.  Based on your analysis, provide a high-level recommendation for the most impactful refactoring to tackle first.
```

## 6. References

*   **[Jules Official Documentation](https://jules.google/docs/)**: The primary source for information on Jules, its features, and how to use it.
*   **[Jules Awesome Prompts](https://github.com/google-labs-code/jules-awesome-list)**: A curated list of effective prompts for a wide variety of development tasks.
